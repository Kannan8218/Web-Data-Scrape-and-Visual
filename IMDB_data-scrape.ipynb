{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import re\n",
    "import sqlite3\n",
    "class IMDB:\n",
    "    def __init__(self):#initialized class variable\n",
    "        self.mergeData = \"\"\n",
    "        self.genres = [\"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\"]\n",
    "        self.urls = [\"https://www.imdb.com/search/title/?title_type=feature&genres=action&release_date=2024-01-01,2024-12-31\",\n",
    "            \"https://www.imdb.com/search/title/?title_type=feature&genres=adventure&release_date=2024-01-01,2024-12-31\",\n",
    "            \"https://www.imdb.com/search/title/?title_type=feature&genres=animation&release_date=2024-01-01,2024-12-31\",\n",
    "            \"https://www.imdb.com/search/title/?title_type=feature&genres=comedy&release_date=2024-01-01,2024-12-31\",\n",
    "            \"https://www.imdb.com/search/title/?title_type=feature&genres=crime&release_date=2024-01-01,2024-12-31\"]\n",
    "        try:\n",
    "            self.driver = webdriver.Chrome() #create web driver\n",
    "            print(\"Initilized: Crome Web-driver Successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Error -> Crome Web-driver Initializing[__init__() function]\\n\\tERROR: \",e)      \n",
    "        try:#Title,Duration,Rating,Votes,Genre\n",
    "            self.conn = sqlite3.connect('IMDB.db') #database created\n",
    "            self.cursor = self.conn.cursor()\n",
    "            print(\"Initilized: Database Successfully\")\n",
    "            self.cursor.execute('''CREATE TABLE IF NOT EXISTS Movies (Title TEXT,Duration FLOAT,Rating FLOAT,Votes INT,Genre TEXT)''')\n",
    "            print(\"Database Table create successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Error -> Database Initializing[__init__() function]\\n\\tERROR: \",e)\n",
    "    def store_data(self):\n",
    "        try:#insert multiple rows into database table  #Title,Duration,Rating,Votes,Genre\n",
    "            try:\n",
    "                self.cursor.executemany(\"INSERT INTO Movies (Title, Duration, Rating, Votes, Genre) VALUES (?, ?, ?, ?, ?)\", self.mergeData.itertuples(index=False, name=None))\n",
    "                self.conn.commit()\n",
    "            except Exception as e:\n",
    "                print(\"Error - Insert data into Database[store_data() function]\\n\\tERROR: \",e)\n",
    "                return False\n",
    "            print(\"Cleaned data from the IMDB website was successfully inserted into the database table\")\n",
    "            print(\"Here, Sample data fron Database\")\n",
    "            a = self.cursor.execute(\"SELECT * FROM Movies LIMIT 5\") #check insert rows successfully inserted or not\n",
    "            for i in a:\n",
    "                print(i)\n",
    "            self.cursor.execute(\"PRAGMA table_info(Movies);\")\n",
    "            columns = self.cursor.fetchall()\n",
    "            # Print column names and data types\n",
    "            print(\"Column Name | Data Type\")\n",
    "            print(\"-\" * 30)\n",
    "            for col in columns:\n",
    "                print(f\"{col[1]} | {col[2]}\")\n",
    "            self.conn.close()\n",
    "            print(\"cleaned data from IMDB website inseted into database table successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Error - [store_data() function]\\n\\tERROR: \",e)\n",
    "            return False\n",
    "        return True\n",
    "    def merge_data(self):\n",
    "        try:\n",
    "            d = [pd.read_csv(f\"{i}-1.csv\") for i in self.genres] # csv file already in Genre list, then append .csv \n",
    "        except Exception as e:\n",
    "            print(f\"Error â†’ Unable to read all CSV files [merge_data() function]\\n\\tERROR:\",e)\n",
    "            return False\n",
    "        self.mergeData = pd.concat(d, ignore_index=True)\n",
    "        self.mergeData.drop_duplicates(subset=['Title', 'Duration', 'Rating','Votes','Genre'], keep='first', inplace=True) # delete dupulicate data's\n",
    "        print(\"Info of Merged data in DataFrame:\",'\\n',self.mergeData.info())#print dataframe information\n",
    "        print(f\"count:{'\\n'}{self.mergeData.count()}\") #printhow many data in after merge all csv files into dataframe\n",
    "        self.mergeData.to_csv(f\"merge_data.csv\", index=False)  #save scraped data into csv file\n",
    "        print(\"merge_data.csv was created successfully\")\n",
    "        return True\n",
    "    def change_Title(self,title):\n",
    "        if pd.isna(title):\n",
    "            return None\n",
    "        title = re.sub(r'^\\d+\\.\\s*', '', title) #remove index number(1.,2.,3.,....)\n",
    "        return title.strip()\n",
    "    def change_Duration(self,duration):  \n",
    "        if pd.isna(duration): \n",
    "            return 0.0\n",
    "        hours, minutes = 0, 0\n",
    "        if \"h\" in duration:\n",
    "            hours = int(duration.split(\"h\")[0].strip())  \n",
    "        if \"m\" in duration:\n",
    "            minutes = int(duration.split(\"h\")[-1].replace(\"m\", \"\").strip())  \n",
    "        return float(f\"{hours}.{minutes:02d}\")\n",
    "    def change_votes(self,vote):\n",
    "        if pd.isna(vote): \n",
    "            return 0\n",
    "        if isinstance(vote, str):\n",
    "            vote = vote.strip(\"() \").replace(\",\", \"\")  \n",
    "            if vote.isdigit():  \n",
    "                return int(vote)\n",
    "            multiplier = 1\n",
    "            if \"K\" in vote:\n",
    "                multiplier = 1000\n",
    "                vote = vote.replace(\"K\", \"\")\n",
    "            elif \"M\" in vote:\n",
    "                multiplier = 1000000\n",
    "                vote = vote.replace(\"M\", \"\")\n",
    "            elif \"B\" in vote:\n",
    "                multiplier = 1000000000\n",
    "                vote = vote.replace(\"B\", \"\")\n",
    "            try:\n",
    "                return int(float(vote) * multiplier) \n",
    "            except ValueError:\n",
    "                return 0  \n",
    "        return 0 \n",
    "    def clean_data(self):\n",
    "        for i in self.genres: #clean datas in csv files using loop statement\n",
    "            try:\n",
    "                a = pd.read_csv(f\"{i}.csv\")# read csv files \n",
    "            except Exception as e:\n",
    "                print(f\"Error -> read {i}.csv file[clean_data() function]\\n\\tERROR: \",e)\n",
    "                return False\n",
    "            a[\"Title\"] = a[\"Title\"].apply(self.change_Title).astype(\"str\").str.replace(\"'\", \"\") # remove number, dot(.), and strip the value\n",
    "            a[\"Duration\"] = a[\"Duration\"].apply(self.change_Duration)#  change duration \n",
    "            a[\"Rating\"] = pd.to_numeric(a[\"Rating\"], errors=\"coerce\").fillna(0.0).astype(\"float64\")#   change Rating datatype\n",
    "            a[\"Votes\"] = a[\"Votes\"].apply(self.change_votes).astype(\"Int64\")# change votes\n",
    "            a[\"Genre\"] = a[\"Genre\"].astype(\"str\")#   change gener datatype\n",
    "            a.drop_duplicates(subset=['Title', 'Duration', 'Rating','Votes','Genre'], keep='first', inplace=True) # delete dupulicate data's\n",
    "            a = a[(a != 0).all(axis=1)] # remove row if any row value is 0(zero)\n",
    "            a.to_csv(f\"{i}-1.csv\", index=False)\n",
    "            print(a.info())\n",
    "            print(f\"Cleaned data in the {i}.csv file and stored it in {i}-1.csv successfully\")\n",
    "        return True    \n",
    "    def scrape_data(self,url):\n",
    "        data_dict = {'Title': [], 'Duration': [], 'Rating': [], 'Votes': []}\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            print(\"URL link loaded into the web driver\")\n",
    "        except Exception as e:\n",
    "            print(\"Error -> load URL link[scrape_data() function]\\n\\tERROR: \",e)\n",
    "            return False\n",
    "        time.sleep(3)\n",
    "        print(\"Starting to click '50 more' buttons\")  \n",
    "        while True:\n",
    "            try:\n",
    "                load_more = self.driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button')\n",
    "                ActionChains(self.driver).move_to_element(load_more).perform()\n",
    "                load_more.click()\n",
    "                time.sleep(3)\n",
    "            except Exception as e:\n",
    "                print(\"click '50 more' buttons process Stopped\")\n",
    "                break\n",
    "        movies_item = self.driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "        temp =0\n",
    "        print(\"Started Extracting Movie's details from the Website\")\n",
    "        for movies in movies_item:\n",
    "            try:\n",
    "                title = movies.find_element(By.XPATH, \"./div/div/div/div[1]/div[2]/div[1]/a/h3\").text\n",
    "                duration = movies.find_element(By.XPATH, \"./div/div/div/div[1]/div[2]/div[2]/span[2]\").text\n",
    "                rating  = movies.find_element(By.XPATH, \"./div/div/div/div[1]/div[2]/span/div/span/span[1]\").text\n",
    "                voting = movies.find_element(By.XPATH, \"./div/div/div/div[1]/div[2]/span/div/span/span[2]\").text\n",
    "                data_dict['Title'].append(title)\n",
    "                data_dict['Rating'].append(rating)\n",
    "                data_dict['Votes'].append(voting)\n",
    "                data_dict['Duration'].append(duration)\n",
    "            except Exception as e:\n",
    "                temp += 1\n",
    "        print(f\"Incomplete - {temp} Movie's details cannot be Extracted from Website\")\n",
    "        return data_dict\n",
    "    def get_data(self): \n",
    "        if self.driver is None:  # Check if web driver is created\n",
    "            print(\"Crome Web-driver not Initialized\")\n",
    "            return False\n",
    "        for i, url in enumerate(self.urls):\n",
    "            print(f\"Scraping {self.genres[i]} movies...\")\n",
    "            data = self.scrape_data(url)\n",
    "            df = pd.DataFrame(data)\n",
    "            df['Genre'] = self.genres[i]\n",
    "            df.to_csv(f\"{self.genres[i]}.csv\", index=False)\n",
    "            print(f\"Scraped {df['Title'].count()} {self.genres[i]} Movie details stored in {self.genres[i]}.csv successfully\")\n",
    "        self.driver.quit()\n",
    "        print(\"Data scraping process completed\")\n",
    "        return True\n",
    "obj = IMDB()\n",
    "if obj.get_data():\n",
    "    if obj.clean_data():\n",
    "        if obj.merge_data():\n",
    "            if obj.store_data():\n",
    "                print(\"Code Execution complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
